{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/lisong/algorithms/graphtranssimulator\")\n",
    "import src\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_EGCN_data(graph_path, num_date_groups=10):\n",
    "    with open(graph_path,'rb') as f:\n",
    "        Generator = pickle.load(f)\n",
    "    g = Generator.g\n",
    "    \n",
    "    # find min_date and max_date\n",
    "    dates = []\n",
    "    for e in g.edges:\n",
    "        dates.append(g.edges[e][\"date\"])\n",
    "    min_date = int(min(dates))\n",
    "    max_date = int(max(dates))\n",
    "    if max_date - min_date < num_date_groups:\n",
    "        raise ValueError(\"Need to set a larger number of groups for \\\"def generate_EGCN_data\\\" to categorize transaction dates\") \n",
    "    \n",
    "    # generate txs_features.csv —— txId, class\n",
    "    with open(\"./FirstTry/txs_features.csv\",\"w\",encoding='UTF8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        tran_index = []\n",
    "        tran_dates = []\n",
    "        tran_amounts = []\n",
    "        for e in g.edges:\n",
    "            tran_index.append(g.edges[e][\"edge_id\"])\n",
    "            tran_dates.append(int(g.edges[e][\"date\"]))\n",
    "            tran_amounts.append(g.edges[e][\"amount\"])\n",
    "        \n",
    "        cat_tran_dates = list(pd.cut(tran_dates, num_date_groups, labels=range(num_date_groups)))\n",
    "        tran_amounts_norm = processing.normalize(tran_amounts)\n",
    "        \n",
    "        for i in range(len(tran_dates)):\n",
    "            writer.writerow([tran_index[i],cat_tran_dates[i],tran_amounts_norm[i]])\n",
    "        \n",
    "    # generate txs_classes.csv —— txId, class\n",
    "    with open(\"./FirstTry/txs_classes.csv\",\"w\",encoding='UTF8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        tran_index = []\n",
    "        tran_class = []\n",
    "        for e in g.edges:\n",
    "            tran_index.append(g.edges[e][\"edge_id\"])\n",
    "\n",
    "        \n",
    "        cat_tran_dates = list(pd.cut(tran_dates, num_date_groups, labels=range(num_date_groups)))\n",
    "        tran_amounts_norm = processing.normalize(tran_amounts)\n",
    "        \n",
    "        for i in range(len(tran_dates)):\n",
    "            writer.writerow([tran_index[i],cat_tran_dates[i],tran_amounts_norm[i]])\n",
    "            \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 2, 2, 3, 3, 4, 4]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "k = 5\n",
    "d1 = pd.cut([1,2,3,4,5,6,7,8,9,10],5,labels=range(k))\n",
    "list(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
